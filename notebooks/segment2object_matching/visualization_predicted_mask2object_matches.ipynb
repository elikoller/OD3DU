{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook visualizes for each frame of the rescan: the predicted match between the segments and reference objects compared to the ground truth match that is excpected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import plyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import sys\n",
    "ws_dir = '/local/home/ekoller/BT' #adjust\n",
    "print(ws_dir)\n",
    "sys.path.append(ws_dir)\n",
    "from utils import scan3r, od3du_utils\n",
    "\n",
    "#adjust the paths as needed\n",
    "data_dir ='/local/home/ekoller/R3Scan'\n",
    "scenes_dir = '/local/home/ekoller/R3Scan/scenes' \n",
    "new_scan_id =  \"74ef846e-9dce-2d66-83d5-294aac7b1b0f\" #choose whatever test rescan Id you want\n",
    "curr_scan_id = scan3r.get_reference_id(data_dir, new_scan_id) #reference scene\n",
    "patch_h= 18\n",
    "image_height = 540\n",
    "image_width = 960\n",
    "patch_w = 32\n",
    "patch_height = 30\n",
    "patch_width = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function creates a color image of the size 960x540 from the patches\n",
    "def create_color_img_from_obj_id(data_dir,scan_id,obj_id_mat):\n",
    "    #access the mesh file to get the colour of the ids\n",
    "    colour_dict = od3du_utils.get_id_colours(data_dir, scan_id)\n",
    "    #initialize the new matrix \n",
    "    og_height, og_width = obj_id_mat.shape\n",
    "    new_height = og_height * patch_height\n",
    "    new_width = og_width * patch_width\n",
    "\n",
    "    colour_mat = np.zeros((new_height,new_width,3))\n",
    "\n",
    "    #go over each element and assign the colour of the dictionary\n",
    "    for h in range(og_height):\n",
    "        for w in range(og_width):\n",
    "            if obj_id_mat[h][w] in colour_dict.keys():\n",
    "                colour = colour_dict[obj_id_mat[h][w]]\n",
    "                colour_mat[h*patch_height:(h+1)*patch_height, w*patch_width:(w+1)*patch_width] = colour\n",
    "\n",
    "\n",
    "    return colour_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access the segmentation info along with the predicted matches\n",
    "segmentation_info_path = osp.join(data_dir, \"files/Segmentation/DinoV2/objects\", new_scan_id + \".h5\")\n",
    "segmentation_info = od3du_utils.read_segmentation_data(segmentation_info_path)\n",
    "id_matches = od3du_utils.read_matching_data(osp.join(data_dir, \"files\"), new_scan_id)\n",
    "\n",
    "for frame, match_list in id_matches.items():\n",
    "    # Extract and store the frame index and corresponding matches\n",
    "\n",
    "    #generate a pixelwise image \n",
    "    new_img_pixelwise = od3du_utils.generate_pixel_level(segmentation_info[frame], match_list, image_height, image_width)\n",
    "\n",
    "    #quantize to patches\n",
    "    new_img_patchwise = od3du_utils.quantize_to_patch_level(new_img_pixelwise, image_height, image_width, patch_h, patch_w)\n",
    "    #aggregate to patches and colour it, we want the colours which are used in curr_scan id / reference scene\n",
    "    new_img_colour = create_color_img_from_obj_id(data_dir,curr_scan_id, new_img_patchwise)\n",
    " \n",
    "    \"\"\"\n",
    "    access the gt of the image and get the accuracy of the prediction, print result and display \n",
    "    \"\"\"\n",
    "    #get the gt patches for the segmented scene! so for the dinov2 segmentation: but the colour will be based on the current scene\n",
    "    gt_input_patchwise_path =  osp.join(data_dir,\"files/patch_anno/patch_anno_32_18\", new_scan_id + '.pkl')\n",
    "    with open(gt_input_patchwise_path, 'rb') as file:\n",
    "        gt_input_patchwise = pickle.load(file)\n",
    "    gt_input_colour = create_color_img_from_obj_id(data_dir,curr_scan_id,gt_input_patchwise[frame])\n",
    "\n",
    "\n",
    "    # \"\"\"\n",
    "    # display the newly computed images & GT next to each other\n",
    "    # \"\"\"\n",
    "\n",
    "    #display the gt_image and the new patchwise image next to each other\n",
    "    title1 = \"gt_patces frame: \" + frame\n",
    "    title2 = \"predicted_patches frame: \" + frame\n",
    "\n",
    "   # Create a blank canvas to combine images horizontally\n",
    "    height = max(gt_input_colour.shape[0], new_img_colour.shape[0])  # Max height of both images\n",
    "    width = gt_input_colour.shape[1] + new_img_colour.shape[1] + 20  # Total width of both images with a small gap\n",
    "    combined_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Place images on the blank canvas\n",
    "    combined_image[:gt_input_colour.shape[0], :gt_input_colour.shape[1]] = gt_input_colour\n",
    "    combined_image[:new_img_colour.shape[0], gt_input_colour.shape[1] + 20:] = new_img_colour\n",
    "\n",
    "    # Add titles to the images\n",
    "    cv2.putText(combined_image, title1, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(combined_image, title2, (gt_input_colour.shape[1] + 30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Use matplotlib to display the combined image\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(cv2.cvtColor(combined_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
