{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "/local/home/ekoller/BT\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os \n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import plyfile\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import h5py\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os.path as osp\n",
    "import sys\n",
    "ws_dir = '/local/home/ekoller/BT'\n",
    "print(ws_dir)\n",
    "sys.path.append(ws_dir)\n",
    "from utils import evaluation, scan3r\n",
    "\n",
    "\n",
    "data_dir ='/local/home/ekoller/R3Scan'\n",
    "scenes_dir = '/local/home/ekoller/R3Scan/scenes'\n",
    "#scan_id= \"38770c95-86d7-27b8-8717-3485b411ddc7\" #is reference scan  since it is a reference scan everything shouls be correctly hit\n",
    "#curr_scan_id =  \"02b33e01-be2b-2d54-93fb-4145a709cec5\"#\"02b33e01-be2b-2d54-93fb-4145a709cec5\" \n",
    "new_scan_id =  \"fcf66d8a-622d-291c-8429-0e1109c6bb26\" #\"fcf66d88-622d-291c-871f-699b2d063630\" #\"fcf66d8a-622d-291c-8429-0e1109c6bb26\"\n",
    "curr_scan_id = scan3r.get_reference_id(data_dir,new_scan_id)\n",
    "frame_number = \"000007\"\n",
    "curr_frame_number = \"000007\"\n",
    "new_frame_number = \"000008\"\n",
    "patch_h= 18\n",
    "image_height = 540\n",
    "image_width = 960\n",
    "patch_w = 32\n",
    "patch_height = 30\n",
    "patch_width = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualitation of the following: with the new ids fill in an image with the new ids\n",
    "#compute the resulting image when comparing stuff\n",
    "\n",
    "def generate_pairs_pixel_level( dino_data,id_matches):\n",
    "    \n",
    "    new_ids = np.zeros((image_height, image_width))\n",
    "\n",
    "\n",
    "    #go over every mask and fill in the id into the new_ids which it got mapped to\n",
    "    for seg_region in dino_data:\n",
    "        mask_id = seg_region[\"object_id\"]\n",
    "        \n",
    "        #print(\"mask id \", mask_id)\n",
    "        #get to what the region mapped in the embeddings\n",
    "        matched_id = id_matches[str(mask_id)]\n",
    "        #print(\"matched id \", matched_id)\n",
    "        mask = seg_region[\"mask\"]\n",
    "        boolean_mask = mask == 225\n",
    "        new_ids[boolean_mask] = matched_id #[0] is the id the second one is the error\n",
    "        #visualize(boolean_mask, new_ids, f'Updated new_ids with mask id {mask_id}')\n",
    "\n",
    "    #returns the new ids on a pixel wise level\n",
    "    return new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this codesegment takes an image on a pixel wise level and quantizes it such that every patch has only the id of the most often occuring id\n",
    "def quantize_to_patch_level(pixelwise_img):\n",
    "    #get the shape of the pixelwise img\n",
    "    input_h, input_w = pixelwise_img.shape\n",
    "    patch_width = int(input_w/patch_w)\n",
    "    patch_height= int(input_h/patch_h)\n",
    "\n",
    "    patchwise_w = patch_w #number of patches\n",
    "    patchwise_h = patch_h\n",
    "\n",
    "    patchwise_id = np.zeros((patchwise_h,patchwise_w))\n",
    "\n",
    "    for i in range(patchwise_h):\n",
    "            for j in range(patchwise_w):\n",
    "                # Define the coordinates of the current patch\n",
    "                h_start = i * patch_height\n",
    "                w_start = j * patch_width\n",
    "                h_end = h_start + patch_height\n",
    "                w_end = w_start + patch_width\n",
    "                \n",
    "                # Get the current patch from the input matrix\n",
    "                patch = pixelwise_img[h_start:h_end, w_start:w_end]\n",
    "                \n",
    "                # get the most reoccuring id of the patch\n",
    "                flattened_patch = patch.flatten()\n",
    "                # Find the most common value in the patch\n",
    "                value_counts = Counter(flattened_patch)\n",
    "                most_common_id = value_counts.most_common(1)[0][0]\n",
    "                \n",
    "                # Assign the most common ID to the new matrix\n",
    "                patchwise_id[i, j] = most_common_id\n",
    "\n",
    "\n",
    "    return patchwise_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur scan id colors dict_keys([4, 18, 2, 0, 3, 1, 100, 16, 8, 9, 24, 25, 29, 6, 26, 10, 11, 23, 27, 22, 5, 20, 12, 15, 13, 14, 103, 21])\n",
      "new scan id colors dict_keys([13, 20, 1, 4, 100, 6, 14, 15, 18, 29, 5, 8, 16, 105, 0])\n"
     ]
    }
   ],
   "source": [
    "#for a given scene get the colours of the differnt object_ids\n",
    "def get_id_colours(data_dir,scan_id):\n",
    "    #access the mesh file to get the colour of the ids\n",
    "    mesh_file = osp.join(data_dir,\"scenes\", scan_id, \"labels.instances.annotated.v2.ply\")\n",
    "    ply_data = plyfile.PlyData.read(mesh_file)\n",
    "    # Extract vertex data\n",
    "    vertices = ply_data['vertex']\n",
    "    vertex_count = len(vertices)\n",
    "    \n",
    "    # Initialize dictionary to store object_id -> color mappings\n",
    "    object_colors = {}\n",
    "    \n",
    "   # Iterate through vertices\n",
    "    for i in range(vertex_count):\n",
    "        vertex = vertices[i]\n",
    "        object_id = vertex['objectId']\n",
    "        color = (vertex['red'], vertex['green'], vertex['blue'])\n",
    "        \n",
    "        # Check if object_id already in dictionary, otherwise initialize a Counter\n",
    "        if object_id in object_colors:\n",
    "            object_colors[object_id][color] += 1\n",
    "        else:\n",
    "            object_colors[object_id] = Counter({color: 1})\n",
    "    \n",
    "    # Convert Counter to dictionary with most frequent color\n",
    "    for object_id, color_counter in object_colors.items():\n",
    "        most_common_color = color_counter.most_common(1)[0][0]\n",
    "        object_colors[object_id] = np.array(most_common_color)\n",
    "    \n",
    "    return object_colors\n",
    "\n",
    "colors = get_id_colours(data_dir,curr_scan_id)\n",
    "print(\"cur scan id colors\", colors.keys())\n",
    "colors = get_id_colours(data_dir,new_scan_id)\n",
    "print(\"new scan id colors\", colors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function creates a color image of the size 960x540 from the patches\n",
    "def create_color_img_from_obj_id(data_dir,scan_id,obj_id_mat):\n",
    "    #access the mesh file to get the colour of the ids\n",
    "    colour_dict = get_id_colours(data_dir, scan_id)\n",
    "    #initialize the new matrix \n",
    "    og_height, og_width = obj_id_mat.shape\n",
    "    new_height = og_height * patch_height\n",
    "    new_width = og_width * patch_width\n",
    "\n",
    "    colour_mat = np.zeros((new_height,new_width,3))\n",
    "\n",
    "    #go over each element and assign the colour of the dictionary\n",
    "    for h in range(og_height):\n",
    "        for w in range(og_width):\n",
    "            if obj_id_mat[h][w] in colour_dict.keys():\n",
    "                colour = colour_dict[obj_id_mat[h][w]]\n",
    "                colour_mat[h*patch_height:(h+1)*patch_height, w*patch_width:(w+1)*patch_width] = colour\n",
    "\n",
    "\n",
    "    return colour_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique numbers in new img patchwise  [ 1.  4. 14. 29.]\n",
      "unique numbers in new img patchwise  [ 1.  4. 14. 29.]\n",
      "unique numbers in new img patchwise  [ 1.  4.  6. 16. 29.]\n",
      "unique numbers in new img patchwise  [ 1.  4.  6. 24. 29.]\n",
      "unique numbers in new img patchwise  [ 1.  4. 16. 18. 29.]\n",
      "unique numbers in new img patchwise  [ 1.  4. 13. 14. 15. 29.]\n",
      "unique numbers in new img patchwise  [ 1.  4. 13. 14. 15. 18. 26. 29.]\n",
      "unique numbers in new img patchwise  [ 1.  4. 13. 14. 15. 26. 29.]\n",
      "unique numbers in new img patchwise  [ 1.  4. 13. 14. 15. 16. 26. 29.]\n",
      "unique numbers in new img patchwise  [  1.   4.  13.  14.  15.  26.  29. 103.]\n",
      "unique numbers in new img patchwise  [ 1.  3.  4. 13. 14. 15. 18. 26. 29.]\n",
      "unique numbers in new img patchwise  [ 4.  6. 13. 14.]\n",
      "unique numbers in new img patchwise  [ 1.  4.  6. 13. 14. 16. 26.]\n",
      "unique numbers in new img patchwise  [  1.   4.  11.  14.  29. 100.]\n",
      "unique numbers in new img patchwise  [ 1.  3.  4.  5. 14. 26. 29.]\n",
      "unique numbers in new img patchwise  [ 1.  4. 13. 14. 15. 16. 26. 29.]\n",
      "unique numbers in new img patchwise  [ 1.  4. 13. 14. 15. 26. 29.]\n",
      "unique numbers in new img patchwise  [  4.   5.   9.  13.  14.  16.  20. 100.]\n",
      "unique numbers in new img patchwise  [  1.   4.  13.  14.  26. 100.]\n"
     ]
    }
   ],
   "source": [
    "#access the segmentation info\n",
    "\n",
    "segmentation_info = {}\n",
    "segmentation_info_path = osp.join(\"/media/ekoller/T7/Segmentation/DinoV2/objects\", new_scan_id + \".h5\")\n",
    "with h5py.File(segmentation_info_path, 'r') as hdf_file:\n",
    "             for frame_idx in hdf_file.keys():\n",
    "                #init boxlist for curr frame\n",
    "                bounding_boxes = []\n",
    "                \n",
    "                # get info \n",
    "                frame_group = hdf_file[frame_idx]\n",
    "                \n",
    "                #iterate over each boundingbox\n",
    "                for bbox_key in frame_group.keys():\n",
    "                    bbox_group = frame_group[bbox_key]\n",
    "                    \n",
    "                    #get te obj id\n",
    "                    object_id = bbox_group.attrs['object_id']\n",
    "                    \n",
    "                    #get the boundingbox\n",
    "                    bbox = bbox_group['bbox'][:]\n",
    "                    \n",
    "                    # get the maskt\n",
    "                    mask = bbox_group['mask'][:]\n",
    "                    \n",
    "                    # append to list\n",
    "                    bounding_boxes.append({\n",
    "                        'object_id': object_id,\n",
    "                        'bbox': bbox,\n",
    "                        'mask': mask\n",
    "                    })\n",
    "                \n",
    "                # stor it to the corresponding frame\n",
    "                segmentation_info[frame_idx] = bounding_boxes\n",
    "\n",
    "\n",
    "id_matches = {}\n",
    "matches_path = osp.join(\"/local/home/ekoller/R3Scan/Predicted_Matches\", new_scan_id + \".h5\")\n",
    "with h5py.File(matches_path, 'r') as hdf_file:\n",
    "            id_matches = {}\n",
    "            \n",
    "            # Iterate through frame indices\n",
    "            for frame_idx in hdf_file.keys():\n",
    "                matches = {}\n",
    "                \n",
    "                # Access the group for each frame index\n",
    "                frame_group = hdf_file[frame_idx]\n",
    "                \n",
    "                # Load the frame_id -> obj mappings\n",
    "                for frame_id in frame_group.keys():\n",
    "                    obj = frame_group[frame_id][()]\n",
    "                    matches[frame_id] = int(obj)  # Convert back to int\n",
    "                \n",
    "                id_matches[frame_idx] = matches\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "for frame, match_list in id_matches.items():\n",
    "    # Extract and store the frame index and corresponding matches\n",
    "\n",
    "    #assign each pixel to the new value, curr_scan_id , frame number is only for the size\n",
    "    new_img_pixelwise = generate_pairs_pixel_level(segmentation_info[frame], match_list)\n",
    "\n",
    "    #quantize to patches\n",
    "    new_img_patchwise = quantize_to_patch_level(new_img_pixelwise)\n",
    "    #aggregate to patches and colour it, we want the colours which are used in curr_scan id\n",
    "    new_img_colour = create_color_img_from_obj_id(data_dir,curr_scan_id, new_img_patchwise)\n",
    "    print(\"unique numbers in new img patchwise \", np.unique(new_img_patchwise))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    access the gt of the image and get the accuracy of the prediction, print result and display \n",
    "    \"\"\"\n",
    "    #get the gt patches for the segmented scene! so for the dinov2 segmentation: but the colour will be based on the current scene\n",
    "    gt_input_patchwise_path =  osp.join(data_dir,\"files/patch_anno/patch_anno_32_18\", new_scan_id + '.pkl')\n",
    "    with open(gt_input_patchwise_path, 'rb') as file:\n",
    "        gt_input_patchwise = pickle.load(file)\n",
    "    #print(\"unique numbers in gt_input_colour \", np.unique(gt_input_patchwise[frame]))\n",
    "    gt_input_colour = create_color_img_from_obj_id(data_dir,curr_scan_id,gt_input_patchwise[frame])\n",
    "\n",
    "\n",
    "    # \"\"\"\n",
    "    # display the newly computed images next to each other\n",
    "    # \"\"\"\n",
    "\n",
    "    #display the gt_image and the new patchwise image next to each other\n",
    "    title1 = \"gt_patces\"\n",
    "    title2 = \"predicted_patches\"\n",
    "\n",
    "\n",
    "    # Create a blank canvas to combine images horizontally\n",
    "    height = max(gt_input_colour.shape[0], new_img_colour.shape[0])  # Max height of both images\n",
    "    width = gt_input_colour.shape[1] + new_img_colour.shape[1] + 20  # Total width of both images with a small gap\n",
    "    combined_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Place images with titles on the blank canvas\n",
    "    combined_image[:gt_input_colour.shape[0], :gt_input_colour.shape[1]] = gt_input_colour\n",
    "    combined_image[:new_img_colour.shape[0], gt_input_colour.shape[1] + 20:] = new_img_colour\n",
    "\n",
    "    # Add titles to the images\n",
    "    cv2.putText(combined_image, title1, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(combined_image, title2, (gt_input_colour.shape[1] + 30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the combined image\n",
    "    cv2.imshow('Two Images Side by Side', combined_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
