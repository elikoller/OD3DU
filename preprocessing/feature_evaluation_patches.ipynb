{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local/home/ekoller/BT\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import os \n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import plyfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os.path as osp\n",
    "import sys\n",
    "ws_dir = '/local/home/ekoller/BT'\n",
    "print(ws_dir)\n",
    "sys.path.append(ws_dir)\n",
    "from utils import evaluation\n",
    "\n",
    "data_dir ='/local/home/ekoller/R3Scan'\n",
    "scenes_dir = '/local/home/ekoller/R3Scan/scenes'\n",
    "#scan_id= \"38770c95-86d7-27b8-8717-3485b411ddc7\" #is reference scan  since it is a reference scan everything shouls be correctly hit\n",
    "curr_scan_id = \"02b33e01-be2b-2d54-93fb-4145a709cec5\" \n",
    "new_scan_id =  \"fcf66d8a-622d-291c-8429-0e1109c6bb26\"\n",
    "frame_number = \"000008\"\n",
    "curr_frame_number = \"000008\"\n",
    "new_frame_number = \"000007\"\n",
    "patch_h= 9\n",
    "patch_w = 16\n",
    "patch_height = 60\n",
    "patch_width = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given the following: for the input image we have patchwise features. each patch has the same size. as the current image we have for each object in the scene the patch the following: a feature vector which is the average vector obtained by also dividing the image into the same size patches and then taking the vectors of the patches which belong to the objects based on the gt anno 2d\n",
    "there is also a threshold involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine similarity between 2 vectors\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    return dot_product / (norm_vector1 * norm_vector2)\n",
    "\n",
    "\n",
    "#iterate over each patch and for each patch give back the matched id. \n",
    "#assuming on a frame level not whole scan\n",
    "def of_all_find_closes_pairs(obj_patches, patches):\n",
    "    closest_object = np.zeros((patch_h,patch_w))\n",
    "    closest_distance = np.zeros((patch_h,patch_w))\n",
    "   \n",
    "    #go over the image dict since we want to get the closest match of all the ids\n",
    "    for h in range(patch_h):\n",
    "        for w in range(patch_w):\n",
    "            #initialize everything for this round\n",
    "            min_distance = -1\n",
    "            closest_id = None\n",
    "            #access the patch feature\n",
    "            patch_features = patches[h][w]\n",
    "\n",
    "            #iterate over the object embeddings\n",
    "            for obj_id in obj_patches:\n",
    "                object_featrues = obj_patches[obj_id]\n",
    "\n",
    "                #print(\"obj id vec shape\", obj_vec.shape)\n",
    "                #print(\"img id vec shape\", img_vec.shape)\n",
    "                cosine_similarity_all_patches = [cosine_similarity(object_featrues[i], patch_features[i]) for i in range(patch_features.shape[0])]\n",
    "                average_cosine_similarity = np.mean(cosine_similarity_all_patches)\n",
    "             \n",
    "          \n",
    "           \n",
    "                #update\n",
    "                if average_cosine_similarity> min_distance:\n",
    "                    #print(\"update\", average_cosine_similarity, \"for patch \", h, \"_\", w)\n",
    "                    min_distance = average_cosine_similarity\n",
    "                    closest_id= obj_id\n",
    "\n",
    "            #set the values for the image\n",
    "            print(\" final object id\", closest_id, \"for patch \", h, \"_\", w)\n",
    "            closest_object[h][w] = closest_id\n",
    "            closest_distance[h][w] = min_distance\n",
    " \n",
    "\n",
    "        #closest_pairs[img_id] = (closest_id, min_distance)\n",
    "\n",
    "    return closest_object, closest_distance\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur scan id colors 28\n",
      "new scan id colors 15\n"
     ]
    }
   ],
   "source": [
    "#for a given scene get the colours of the differnt object_ids\n",
    "def get_id_colours(data_dir,scan_id):\n",
    "    #access the mesh file to get the colour of the ids\n",
    "    mesh_file = osp.join(data_dir,\"scenes\", scan_id, \"labels.instances.annotated.v2.ply\")\n",
    "    ply_data = plyfile.PlyData.read(mesh_file)\n",
    "    # Extract vertex data\n",
    "    vertices = ply_data['vertex']\n",
    "    vertex_count = len(vertices)\n",
    "    \n",
    "    # Initialize dictionary to store object_id -> color mappings\n",
    "    object_colors = {}\n",
    "    \n",
    "   # Iterate through vertices\n",
    "    for i in range(vertex_count):\n",
    "        vertex = vertices[i]\n",
    "        object_id = vertex['objectId']\n",
    "        color = (vertex['red'], vertex['green'], vertex['blue'])\n",
    "        \n",
    "        # Check if object_id already in dictionary, otherwise initialize a Counter\n",
    "        if object_id in object_colors:\n",
    "            object_colors[object_id][color] += 1\n",
    "        else:\n",
    "            object_colors[object_id] = Counter({color: 1})\n",
    "    \n",
    "    # Convert Counter to dictionary with most frequent color\n",
    "    for object_id, color_counter in object_colors.items():\n",
    "        most_common_color = color_counter.most_common(1)[0][0]\n",
    "        object_colors[object_id] = np.array(most_common_color[::-1])\n",
    "    \n",
    "    return object_colors\n",
    "\n",
    "colors = get_id_colours(data_dir,curr_scan_id)\n",
    "print(\"cur scan id colors\", len(colors.keys()))\n",
    "colors = get_id_colours(data_dir,new_scan_id)\n",
    "print(\"new scan id colors\", len(colors.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function creates a color image of the size 960x540 from the patches\n",
    "def create_color_img_from_obj_id(data_dir,scan_id,obj_id_mat):\n",
    "    #access the mesh file to get the colour of the ids\n",
    "    colour_dict = get_id_colours(data_dir, scan_id)\n",
    "    #initialize the new matrix \n",
    "    og_height, og_width = obj_id_mat.shape\n",
    "    new_height = og_height * patch_height\n",
    "    new_width = og_width * patch_width\n",
    "\n",
    "    colour_mat = np.zeros((new_height,new_width,3))\n",
    "\n",
    "    #go over each element and assign the colour of the dictionary\n",
    "    for h in range(og_height):\n",
    "        for w in range(og_width):\n",
    "            id = obj_id_mat[h][w]\n",
    "            colour = colour_dict[id]\n",
    "            colour_mat[h*patch_height:(h+1)*patch_height, w*patch_width:(w+1)*patch_width] = colour\n",
    "\n",
    "\n",
    "    return colour_mat\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a gt patchwise matrix and a newly calculated matrix compute the accuracy\n",
    "def get_accuracy(gt_patches, computed_patches):\n",
    "    #make sure we dont do something dumm lol\n",
    "    assert gt_patches.shape == computed_patches.shape, \"Matrices must have the same shape\"\n",
    "\n",
    "    # Flatten matrices to iterate over each element\n",
    "    flat_gt = gt_patches.flatten()\n",
    "    flat_comp = computed_patches.flatten()\n",
    "    \n",
    "    total_instances = len(flat_gt)\n",
    "    correct_instances = 0\n",
    "    \n",
    "    # Count correct instances where IDs match\n",
    "    for id_gt, id_comp in zip(flat_gt, flat_comp):\n",
    "        if id_gt == id_comp:\n",
    "            correct_instances += 1\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = correct_instances / total_instances\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of curent features of object (81, 1536)\n",
      "size of input patch features 18 32\n",
      " final object id 4 for patch  0 _ 0\n",
      " final object id 4 for patch  0 _ 1\n",
      " final object id 4 for patch  0 _ 2\n",
      " final object id 4 for patch  0 _ 3\n",
      " final object id 4 for patch  0 _ 4\n",
      " final object id 4 for patch  0 _ 5\n",
      " final object id 4 for patch  0 _ 6\n",
      " final object id 4 for patch  0 _ 7\n",
      " final object id 4 for patch  0 _ 8\n",
      " final object id 4 for patch  0 _ 9\n",
      " final object id 15 for patch  0 _ 10\n",
      " final object id 15 for patch  0 _ 11\n",
      " final object id 15 for patch  0 _ 12\n",
      " final object id 4 for patch  0 _ 13\n",
      " final object id 15 for patch  0 _ 14\n",
      " final object id 15 for patch  0 _ 15\n",
      " final object id 4 for patch  1 _ 0\n",
      " final object id 4 for patch  1 _ 1\n",
      " final object id 15 for patch  1 _ 2\n",
      " final object id 4 for patch  1 _ 3\n",
      " final object id 4 for patch  1 _ 4\n",
      " final object id 4 for patch  1 _ 5\n",
      " final object id 4 for patch  1 _ 6\n",
      " final object id 4 for patch  1 _ 7\n",
      " final object id 4 for patch  1 _ 8\n",
      " final object id 4 for patch  1 _ 9\n",
      " final object id 15 for patch  1 _ 10\n",
      " final object id 15 for patch  1 _ 11\n",
      " final object id 4 for patch  1 _ 12\n",
      " final object id 15 for patch  1 _ 13\n",
      " final object id 15 for patch  1 _ 14\n",
      " final object id 15 for patch  1 _ 15\n",
      " final object id 4 for patch  2 _ 0\n",
      " final object id 4 for patch  2 _ 1\n",
      " final object id 4 for patch  2 _ 2\n",
      " final object id 4 for patch  2 _ 3\n",
      " final object id 4 for patch  2 _ 4\n",
      " final object id 4 for patch  2 _ 5\n",
      " final object id 4 for patch  2 _ 6\n",
      " final object id 4 for patch  2 _ 7\n",
      " final object id 4 for patch  2 _ 8\n",
      " final object id 4 for patch  2 _ 9\n",
      " final object id 15 for patch  2 _ 10\n",
      " final object id 15 for patch  2 _ 11\n",
      " final object id 15 for patch  2 _ 12\n",
      " final object id 15 for patch  2 _ 13\n",
      " final object id 15 for patch  2 _ 14\n",
      " final object id 15 for patch  2 _ 15\n",
      " final object id 4 for patch  3 _ 0\n",
      " final object id 15 for patch  3 _ 1\n",
      " final object id 4 for patch  3 _ 2\n",
      " final object id 4 for patch  3 _ 3\n",
      " final object id 4 for patch  3 _ 4\n",
      " final object id 4 for patch  3 _ 5\n",
      " final object id 4 for patch  3 _ 6\n",
      " final object id 4 for patch  3 _ 7\n",
      " final object id 15 for patch  3 _ 8\n",
      " final object id 15 for patch  3 _ 9\n",
      " final object id 15 for patch  3 _ 10\n",
      " final object id 15 for patch  3 _ 11\n",
      " final object id 4 for patch  3 _ 12\n",
      " final object id 4 for patch  3 _ 13\n",
      " final object id 15 for patch  3 _ 14\n",
      " final object id 4 for patch  3 _ 15\n",
      " final object id 4 for patch  4 _ 0\n",
      " final object id 15 for patch  4 _ 1\n",
      " final object id 4 for patch  4 _ 2\n",
      " final object id 4 for patch  4 _ 3\n",
      " final object id 4 for patch  4 _ 4\n",
      " final object id 4 for patch  4 _ 5\n",
      " final object id 4 for patch  4 _ 6\n",
      " final object id 15 for patch  4 _ 7\n",
      " final object id 15 for patch  4 _ 8\n",
      " final object id 15 for patch  4 _ 9\n",
      " final object id 15 for patch  4 _ 10\n",
      " final object id 15 for patch  4 _ 11\n",
      " final object id 4 for patch  4 _ 12\n",
      " final object id 15 for patch  4 _ 13\n",
      " final object id 4 for patch  4 _ 14\n",
      " final object id 4 for patch  4 _ 15\n",
      " final object id 4 for patch  5 _ 0\n",
      " final object id 4 for patch  5 _ 1\n",
      " final object id 4 for patch  5 _ 2\n",
      " final object id 4 for patch  5 _ 3\n",
      " final object id 4 for patch  5 _ 4\n",
      " final object id 4 for patch  5 _ 5\n",
      " final object id 15 for patch  5 _ 6\n",
      " final object id 4 for patch  5 _ 7\n",
      " final object id 4 for patch  5 _ 8\n",
      " final object id 15 for patch  5 _ 9\n",
      " final object id 15 for patch  5 _ 10\n",
      " final object id 4 for patch  5 _ 11\n",
      " final object id 4 for patch  5 _ 12\n",
      " final object id 4 for patch  5 _ 13\n",
      " final object id 4 for patch  5 _ 14\n",
      " final object id 4 for patch  5 _ 15\n",
      " final object id 15 for patch  6 _ 0\n",
      " final object id 4 for patch  6 _ 1\n",
      " final object id 4 for patch  6 _ 2\n",
      " final object id 4 for patch  6 _ 3\n",
      " final object id 4 for patch  6 _ 4\n",
      " final object id 4 for patch  6 _ 5\n",
      " final object id 4 for patch  6 _ 6\n",
      " final object id 4 for patch  6 _ 7\n",
      " final object id 15 for patch  6 _ 8\n",
      " final object id 4 for patch  6 _ 9\n",
      " final object id 15 for patch  6 _ 10\n",
      " final object id 4 for patch  6 _ 11\n",
      " final object id 4 for patch  6 _ 12\n",
      " final object id 4 for patch  6 _ 13\n",
      " final object id 4 for patch  6 _ 14\n",
      " final object id 4 for patch  6 _ 15\n",
      " final object id 4 for patch  7 _ 0\n",
      " final object id 4 for patch  7 _ 1\n",
      " final object id 4 for patch  7 _ 2\n",
      " final object id 4 for patch  7 _ 3\n",
      " final object id 4 for patch  7 _ 4\n",
      " final object id 4 for patch  7 _ 5\n",
      " final object id 4 for patch  7 _ 6\n",
      " final object id 4 for patch  7 _ 7\n",
      " final object id 4 for patch  7 _ 8\n",
      " final object id 15 for patch  7 _ 9\n",
      " final object id 4 for patch  7 _ 10\n",
      " final object id 4 for patch  7 _ 11\n",
      " final object id 4 for patch  7 _ 12\n",
      " final object id 4 for patch  7 _ 13\n",
      " final object id 13 for patch  7 _ 14\n",
      " final object id 13 for patch  7 _ 15\n",
      " final object id 4 for patch  8 _ 0\n",
      " final object id 4 for patch  8 _ 1\n",
      " final object id 4 for patch  8 _ 2\n",
      " final object id 4 for patch  8 _ 3\n",
      " final object id 4 for patch  8 _ 4\n",
      " final object id 4 for patch  8 _ 5\n",
      " final object id 4 for patch  8 _ 6\n",
      " final object id 4 for patch  8 _ 7\n",
      " final object id 4 for patch  8 _ 8\n",
      " final object id 4 for patch  8 _ 9\n",
      " final object id 4 for patch  8 _ 10\n",
      " final object id 4 for patch  8 _ 11\n",
      " final object id 4 for patch  8 _ 12\n",
      " final object id 13 for patch  8 _ 13\n",
      " final object id 13 for patch  8 _ 14\n",
      " final object id 13 for patch  8 _ 15\n",
      "the accuracy for the current features of the sam boundingboxes vs the gt boundingboxes is 0.2569444444444444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#given a gt patchwise matrix and a newly calculated matrix compute the accuracy\n",
    "def get_accuracy(gt_patches, computed_patches):\n",
    "    #make sure we dont do something dumm lol\n",
    "    assert gt_patches.shape == computed_patches.shape, \"Matrices must have the same shape\"\n",
    "\n",
    "    # Flatten matrices to iterate over each element\n",
    "    flat_gt = gt_patches.flatten()\n",
    "    flat_comp = computed_patches.flatten()\n",
    "    \n",
    "    total_instances = len(flat_gt)\n",
    "    correct_instances = 0\n",
    "    \n",
    "    # Count correct instances where IDs match\n",
    "    for id_gt, id_comp in zip(flat_gt, flat_comp):\n",
    "        if id_gt == id_comp:\n",
    "            correct_instances += 1\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = correct_instances / total_instances\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "new_scan_id = curr_scan_id\n",
    "new_frame_number = frame_number\n",
    "\n",
    "\"\"\"\n",
    "initialize here current = new scan id since we are looking at the gt\n",
    "\"\"\"\n",
    "#read in all the data needed for the evaluation currently this tests the sam input against the ground truth of the input\n",
    "\n",
    "#get the dinofeatures for each patch\n",
    "input_featues_path = osp.join(data_dir,\"files/Features2D/patch/DinoV2\", new_scan_id + \".pkl\")\n",
    "with open(input_featues_path, 'rb') as file:\n",
    "    input_features = pickle.load(file)\n",
    "\n",
    "\n",
    "#get the dino features for each object\n",
    "curr_featues_path = osp.join(data_dir,\"files/Features2D/segmented_patch/DinoV2\", curr_scan_id + \".pkl\")\n",
    "with open(curr_featues_path, 'rb') as file:\n",
    "    curr_features = pickle.load(file)\n",
    "\n",
    "\"\"\"\n",
    "compute the best match for each input on a patchwise level\n",
    "\"\"\"\n",
    "#for each patch compute the corresponding object id, return matrix on patchwise level\n",
    "print(\"size of curent features of object\", curr_features[frame_number][1].shape)\n",
    "print(\"size of input patch features\", len(input_features[new_frame_number]),len(input_features[new_frame_number][0]))\n",
    "id_matches_obj, match_dist = of_all_find_closes_pairs(curr_features[frame_number], input_features[new_frame_number])\n",
    "\n",
    "#print(\"match dist\", match_dist)\n",
    "#print(\"id mathces\", id_matches_obj)\n",
    "\n",
    "new_img_colour = create_color_img_from_obj_id(data_dir,new_scan_id, id_matches_obj)\n",
    "\n",
    "#get the gt input patches and also turn them into bigger images\n",
    "gt_input_patchwise_path =  osp.join(data_dir,\"files/patch_anno/patch_anno_16_9\", new_scan_id + '.pkl')\n",
    "with open(gt_input_patchwise_path, 'rb') as file:\n",
    "    gt_input_patchwise = pickle.load(file)\n",
    "gt_input_colour = create_color_img_from_obj_id(data_dir,new_scan_id,gt_input_patchwise[frame_number])\n",
    "\n",
    "\n",
    "accuracy = get_accuracy(gt_input_patchwise[frame_number],id_matches_obj)\n",
    "print(\"the accuracy for the current features of the sam boundingboxes vs the gt boundingboxes is\", accuracy)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "display the newly computed images next to each other\n",
    "\"\"\"\n",
    "\n",
    "#display the gt_image and the new patchwise image next to each other\n",
    "title1 = \"gt_patces\"\n",
    "title2 = \"predicted_patches\"\n",
    "\n",
    "# Create a blank canvas to combine images horizontally\n",
    "height = max(gt_input_colour.shape[0], new_img_colour.shape[0])  # Max height of both images\n",
    "width = gt_input_colour.shape[1] + new_img_colour.shape[1] + 20  # Total width of both images with a small gap\n",
    "combined_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "# Place images with titles on the blank canvas\n",
    "combined_image[:gt_input_colour.shape[0], :gt_input_colour.shape[1]] = gt_input_colour\n",
    "combined_image[:new_img_colour.shape[0], gt_input_colour.shape[1] + 20:] = new_img_colour\n",
    "\n",
    "# Add titles to the images\n",
    "cv2.putText(combined_image, title1, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(combined_image, title2, (gt_input_colour.shape[1] + 30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "# Display the combined image\n",
    "cv2.imshow('Two Images Side by Side', combined_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
